# ğŸŒŠ Whispers â€“ Mysomania  
*(3D Short Film â€“ 2024 Â· Directed with AI Collaboration)*  

[â† Back to main repository](https://github.com/reusahn/Unity-Unreal-Interaction-Research/tree/main)

---

## ğŸ§© Overview  
**Whispers â€“ Mysomania** is a 3D psychological short film exploring **guilt, moral decay, and survival** through collaborative storytelling between human and AI.  
Three strangers awaken on a drifting raft with no memory of how they arrived.  
As they share mysterious meat to survive, silence begins to expose their hidden guilt â€”  
and those who attempt to rationalize their past gradually vanish into the sea.  

The project was conceived, written, and visually developed through **iterative dialogue with AI systems**, integrating both **creative authorship and machine interpretation** into a single filmmaking process.

---

## âš™ï¸ Technical Description  
- **Engine:** Unreal Engine 5  
- **Software:** MetaHuman Creator Â· Maya Â· Blender Â· Substance Painter Â· DaVinci Resolve  
- **Language:** Blueprint Â· Python (simulation control)  
- **Hardware:** PC (NVIDIA RTX 4090)  
- **AI Tools:** ChatGPT (co-writing & direction) Â· ElevenLabs (AI voice performance) Â· Mubert (AI soundtrack generation)  

### ğŸ§© Pipeline  
1. **Script Development (Humanâ€“AI Dialogue):**  
   The narrative was co-written through iterative discussion with **ChatGPT**, exploring symbolic depictions of guilt, consumption, and silence.  
   The AI contributed structural and tonal variations that shaped the filmâ€™s emotional rhythm.  
2. **Character Creation:**  
   Characters were developed using **MetaHuman Creator**, refined in Maya and Blender for facial nuance and body motion.  
   The voice acting was entirely synthesized through **ElevenLabs**, combining emotional modulation and linguistic precision.  
3. **Scene Design & Simulation:**  
   The drifting raft and ocean environment were built in **Unreal Engine 5**, using the **Water System** and **Chaos Physics** for natural wave interaction.  
   Environmental lighting employed **Lumen** and **Path Tracing** for cinematic realism.  
4. **AI-Guided Postproduction:**  
   AI-generated soundtracks (via **Mubert**) were curated and adjusted through multiple feedback loops between the artist and model.  
   The result reflects a balance between **machine intuition and human editorial control**.  

---

## ğŸ§  Artistic & Research Focus  
**Mysomania** functions as both a **film** and a **meta-experiment in authorship.**  
It questions what it means to *direct* when direction itself is shared with an intelligent system â€”  
challenging traditional hierarchies between filmmaker, performer, and tool.  

The work invites reflection on **AI as co-creator**, not as replacement,  
and proposes a future where emotional tone, ethics, and atmosphere can be co-authored between human intuition and computational reasoning.

---

## ğŸ–¼ï¸ Media
<p align="center">
  <img src="./media/Mysomania_01.jpg" width="40%" style="margin-right:5px;"/>  
  <img src="./media/Mysomania_03.jpg" width="40%" style="margin-right:5px;"/>
</p>

---

## ğŸ¥ Video Documentation
<p align="center">
  <a href="https://vimeo.com/your-video-link-here" target="_blank">
    <img src="./media/Mysomania_Thumb.jpg" width="40%" style="border-radius:10px;"/>
  </a>
  <br>
  <em>Click to view full video on Vimeo</em>
</p>

---

## ğŸ‘¤ Credits  
**Director / Technical Artist:** Jonghoon Ahn  
**AI Collaborator:** ChatGPT (Narrative Co-writing) Â· ElevenLabs (Voice Acting) Â· Mubert (Music Generation)  
**Year:** 2024  
**Institution:** California Institute of the Arts  
**Medium:** 3D Animated Short Film  

---

## ğŸ”— Related  
- [Back to Digital Human & Virtual Beings](../README.md)  
- [View All Projects](https://github.com/reusahn/Unity-Unreal-Interaction-Research/tree/main)
