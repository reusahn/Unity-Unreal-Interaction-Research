# 🌊 Whispers – Mysomania  
*(3D Short Film – 2024 · Directed with AI Collaboration)*  

[← Back to main repository](https://github.com/reusahn/Unity-Unreal-Interaction-Research/tree/main)

---

## 🧩 Overview  
**Whispers – Mysomania** is a 3D psychological short film exploring **guilt, moral decay, and survival** through collaborative storytelling between human and AI.  
Three strangers awaken on a drifting raft with no memory of how they arrived.  
As they share mysterious meat to survive, silence begins to expose their hidden guilt —  
and those who attempt to rationalize their past gradually vanish into the sea.  

The project was conceived, written, and visually developed through **iterative dialogue with AI systems**, integrating both **creative authorship and machine interpretation** into a single filmmaking process.

---

## ⚙️ Technical Description  
- **Engine:** Unreal Engine 5  
- **Software:** MetaHuman Creator · Maya · Blender · Substance Painter · DaVinci Resolve  
- **Language:** Blueprint · Python (simulation control)  
- **Hardware:** PC (NVIDIA RTX 4090)  
- **AI Tools:** ChatGPT (co-writing & direction) · ElevenLabs (AI voice performance) · Mubert (AI soundtrack generation)  

### 🧩 Pipeline  
1. **Script Development (Human–AI Dialogue):**  
   The narrative was co-written through iterative discussion with **ChatGPT**, exploring symbolic depictions of guilt, consumption, and silence.  
   The AI contributed structural and tonal variations that shaped the film’s emotional rhythm.  
2. **Character Creation:**  
   Characters were developed using **MetaHuman Creator**, refined in Maya and Blender for facial nuance and body motion.  
   The voice acting was entirely synthesized through **ElevenLabs**, combining emotional modulation and linguistic precision.  
3. **Scene Design & Simulation:**  
   The drifting raft and ocean environment were built in **Unreal Engine 5**, using the **Water System** and **Chaos Physics** for natural wave interaction.  
   Environmental lighting employed **Lumen** and **Path Tracing** for cinematic realism.  
4. **AI-Guided Postproduction:**  
   AI-generated soundtracks (via **Mubert**) were curated and adjusted through multiple feedback loops between the artist and model.  
   The result reflects a balance between **machine intuition and human editorial control**.  

---

## 🧠 Artistic & Research Focus  
**Mysomania** functions as both a **film** and a **meta-experiment in authorship.**  
It questions what it means to *direct* when direction itself is shared with an intelligent system —  
challenging traditional hierarchies between filmmaker, performer, and tool.  

The work invites reflection on **AI as co-creator**, not as replacement,  
and proposes a future where emotional tone, ethics, and atmosphere can be co-authored between human intuition and computational reasoning.

---

## 🖼️ Media
<p align="center">
  <img src="./media/Mysomania_01.jpg" width="40%" style="margin-right:5px;"/>  
  <img src="./media/Mysomania_03.jpg" width="40%" style="margin-right:5px;"/>
</p>

---

## 🎥 Video Documentation
<p align="center">
  <a href="https://vimeo.com/your-video-link-here" target="_blank">
    <img src="./media/Mysomania_Thumb.jpg" width="40%" style="border-radius:10px;"/>
  </a>
  <br>
  <em>Click to view full video on Vimeo</em>
</p>

---

## 👤 Credits  
**Director / Technical Artist:** Jonghoon Ahn  
**AI Collaborator:** ChatGPT (Narrative Co-writing) · ElevenLabs (Voice Acting) · Mubert (Music Generation)  
**Year:** 2024  
**Institution:** California Institute of the Arts  
**Medium:** 3D Animated Short Film  

---

## 🔗 Related  
- [Back to Digital Human & Virtual Beings](../README.md)  
- [View All Projects](https://github.com/reusahn/Unity-Unreal-Interaction-Research/tree/main)
