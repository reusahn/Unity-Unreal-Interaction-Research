# ğŸ¨ Picasso â€“ AR Self-Portrait Experiment  
*(AR-based Neural Style Transfer Collaboration â€“ 2021 Â· with Junsoo Ha)*  

[â† Back to main repository](https://github.com/reusahn/Unity-Unreal-Interaction-Research/tree/main)

---

## ğŸ§© Overview  
**Picasso** is an AR-based neural style transfer experiment that reinterprets the human face through the fragmented and abstract aesthetics of **Pablo Picassoâ€™s paintings**.  
Developed in collaboration with **Junsoo Ha**, the work transforms real-time camera input into a **cubist-inspired digital portrait**, turning the viewerâ€™s own image into a living artwork.  

By blending AI training and AR visualization, the project explores how **machine perception redefines identity and authorship**â€”  
transforming the front-facing camera into both a **mirror and a painterâ€™s brush**.  
Each stylized face is archived on a secondary display, where audience portraits form a collective visual timeline of machine-mediated self-expression.

---

## âš™ï¸ Technical Description  
- **Engine:** Unity  
- **Framework:** AR Foundation (ARKit)  
- **Software:** Blender Â· Photoshop (dataset curation)  
- **Languages:** C# Â· Python  
- **AI Model:** Custom Neural Style Transfer (TensorFlow â†’ ONNX â†’ Unity Barracuda)  
- **Hardware:** iPhone 12 Â· MacBook Pro (training & deployment)  

### ğŸ§© Pipeline  
1. **Dataset & Model Training:**  
   Selected **five Picasso paintings** representing distinct cubist and color phases.  
   Trained a neural style transfer model for ~1000 steps using TensorFlow, stabilizing the stylistic balance between abstraction and legibility.  
2. **Model Conversion:**  
   Exported trained model as **ONNX** and executed it in Unity via **Barracuda GPU backend** for real-time inference.  
3. **Real-time Face Capture:**  
   Captured userâ€™s face with **AR Foundation** (WebCamTexture â†’ RenderTexture) and applied live style mapping.  
4. **Network & Archiving:**  
   Used **TCP socket communication** to stream stylized portraits to an external screen,  
   creating a **shared archive** of all captured self-portraits as a looping slideshow.  
5. **Performance Optimization:**  
   Implemented half-precision textures and reduced inference latency to **~20ms per frame**, enabling mobile AR fluency.  

---

## ğŸ§  Artistic & Research Focus  
The project explores the **intersection of self-perception, artistic style, and neural translation**.  
By training on Picassoâ€™s paintings and applying them to live faces, the work challenges traditional notions of **portraiture and authorship**â€”  
asking whether a machine can **interpret** rather than merely **replicate** art.  

The archived portraits form a **collective portrait of spectatorship**,  
inviting audiences to see themselvesâ€”and each otherâ€”through a machineâ€™s reinterpretation of art history.

---

## ğŸ–¼ï¸ Media
<p align="center">
  <img src="./media/Picasso_01.jpg" width="15%" style="margin-right:5px;"/>  
  <img src="./media/Picasso_02.jpg" width="15%" style="margin-right:5px;"/>
     <img src="./media/Picasso_03.jpg" width="15%" style="margin-right:5px;"/>  
  <img src="./media/Picasso_04.jpg" width="15%" style="margin-right:5px;"/>
     <img src="./media/Picasso_05.jpg" width="15%" style="margin-right:5px;"/>  
  <img src="./media/Picasso_06.jpg" width="15%" style="margin-right:5px;"/>
</p>

---
<!--
## ğŸ¥ Video Documentation
<p align="center">
  <a href="https://vimeo.com/your-video-link-here" target="_blank">
    <img src="./media/Picasso_Thumb.jpg" width="40%" style="border-radius:10px;"/>
  </a>
  <br>
  <em>Click to view full video on Vimeo</em>
</p>
-->
---

## ğŸ’» Implementation Notes  
- **Model:** Fast Neural Style Transfer (Johnson et al.)  
- **Runtime:** Unity Barracuda (GPU Compute Shader backend)  
- **Networking:** TCP socket for remote archiving display  
- **Performance:** ~18â€“22 ms/frame on iPhone 12 (ARKit pipeline)  
- **Output:** Stylized live portrait + remote slideshow archive  

---

## ğŸ‘¤ Credits  
**Artists / Developers:** Jonghoon Ahn & Junsoo Ha  
**Year:** 2021  
**Institution:** Kookmin University  
**Medium:** AR-based Neural Style Transfer Installation  

---

## ğŸ”— Related  
- [Back to AR-based Style Transfer](../README.md)  
- [View All Projects](https://github.com/reusahn/Unity-Unreal-Interaction-Research/tree/main)
